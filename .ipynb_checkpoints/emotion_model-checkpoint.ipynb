{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "d6a5d000431509f34e5a4dfdca7a8b6594a16b48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anuragsharma/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten, merge, LSTM, Lambda, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D, GlobalAveragePooling1D,GlobalMaxPool1D\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D, concatenate,Concatenate\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "_cell_guid": "c49f4cc4-aa70-41ec-bfad-bf6f00c9d446",
    "_uuid": "34d2dc98c609de470a7d1ab9694576ee9ab7022e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from nltk import word_tokenize, ngrams\n",
    "from nltk.classify import SklearnClassifier\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "np.random.seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "c1f88cb9-0a20-4a92-bd78-1fff07b25e15",
    "_uuid": "aadab28ec4efb4d9384b80c7188c687b2c877b1a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"emotion_trainingdataset.csv\", delimiter='\\t')\n",
    "test = pd.read_csv(\"emotion_testdataset.csv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "6a4a1c3c-0a59-4ebb-8942-9f90085b7458",
    "_uuid": "4b783331a1c972ac13121020dd94acb28e8f72c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sum1 said this would be huge one day...smart guy</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@Rorzshach Oh no  -hugs-</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@biankuh no, im a people pleaser</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@player112345 Good Morrow! How are you this fa...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Darts and lunch at Horse Brass... but no beer ...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review  emotion\n",
       "0           0   Sum1 said this would be huge one day...smart guy  neutral\n",
       "1           1                           @Rorzshach Oh no  -hugs-  sadness\n",
       "2           2                   @biankuh no, im a people pleaser  neutral\n",
       "3           3  @player112345 Good Morrow! How are you this fa...    worry\n",
       "4           4  Darts and lunch at Horse Brass... but no beer ...    worry"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b7dfbde8-7395-4f1d-9d6e-dbbb03b04568",
    "_uuid": "1434058056af0c85e0b9349a99ba6c9c1ee20ebd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e3c7e083-6380-4e5a-a63b-d8e143015527",
    "_uuid": "3d52fa047d79cf2493fd46b39801c4237bbf324b"
   },
   "source": [
    "Let's explore some comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "d3d968f8-56b6-48a8-8f48-67860d22ee13",
    "_uuid": "be8efc3f78339f982611e97559be4503f610cef7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sum1 said this would be huge one day...smart guy'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "16a6740b-bcf4-425f-8c5e-a5358d001147",
    "_uuid": "5f23c4c12ca8c0f39387c98464cbace8d65c2160"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@Rorzshach Oh no  -hugs-'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['review'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "9c418fe3-bac9-4dc5-95e9-a1f95b220d3e",
    "_uuid": "eb2e393cabac8f5e19485f7a6f794c8e683b5aeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "review        0\n",
       "emotion       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9447f20a-6c44-4255-bce1-d0ffd83226f2",
    "_uuid": "3cb447b923f05aa3321fa060e663c2f764e9cc4c"
   },
   "source": [
    "No null values are here. Let's see more about each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral      622\n",
       "worry        586\n",
       "sadness      376\n",
       "happiness    338\n",
       "love         270\n",
       "anger          8\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x107019780>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_target = {'neutral':0, 'worry':1, 'sadness':2, 'happiness':3, 'love':4, 'anger':5}\n",
    "train = train.replace({'emotion':mapping_target})\n",
    "target = train['emotion']\n",
    "test_reviews = test['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean data\n",
    "import string\n",
    "import itertools \n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "### Non-negative stop words.\n",
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves',\n",
    " 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their',\n",
    " 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was',\n",
    " 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and',\n",
    " 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'between',\n",
    " 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on',\n",
    " 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all',\n",
    " 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same',\n",
    " 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', 'now', 'd', 'll', 'm', 'o', 're',\n",
    " 've', 'y', 'ma']\n",
    "\n",
    "def cleanData(text, lowercase = False, remove_stops = False, stemming = False, lemmatization = False):\n",
    "    txt = str(text)\n",
    "    \n",
    "    # Replace apostrophes with standard lexicons\n",
    "    txt = txt.replace(\"isn't\", \"is not\")\n",
    "    txt = txt.replace(\"aren't\", \"are not\")\n",
    "    txt = txt.replace(\"ain't\", \"am not\")\n",
    "    txt = txt.replace(\"won't\", \"will not\")\n",
    "    txt = txt.replace(\"didn't\", \"did not\")\n",
    "    txt = txt.replace(\"shan't\", \"shall not\")\n",
    "    txt = txt.replace(\"haven't\", \"have not\")\n",
    "    txt = txt.replace(\"hadn't\", \"had not\")\n",
    "    txt = txt.replace(\"hasn't\", \"has not\")\n",
    "    txt = txt.replace(\"don't\", \"do not\")\n",
    "    txt = txt.replace(\"wasn't\", \"was not\")\n",
    "    txt = txt.replace(\"weren't\", \"were not\")\n",
    "    txt = txt.replace(\"doesn't\", \"does not\")\n",
    "    txt = txt.replace(\"'s\", \" is\")\n",
    "    txt = txt.replace(\"'re\", \" are\")\n",
    "    txt = txt.replace(\"'m\", \" am\")\n",
    "    txt = txt.replace(\"'d\", \" would\")\n",
    "    txt = txt.replace(\"'ll\", \" will\")\n",
    "    txt = txt.replace(\"--th\", \" \")\n",
    "    \n",
    "    # More cleaning\n",
    "    txt = re.sub(r\"alot\", \"a lot\", txt)\n",
    "    txt = re.sub(r\"what's\", \"\", txt)\n",
    "    txt = re.sub(r\"What's\", \"\", txt)\n",
    "    \n",
    "    \n",
    "    # Remove urls and emails\n",
    "    txt = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', ' ', txt, flags=re.MULTILINE)\n",
    "    txt = re.sub(r'[\\w\\.-]+@[\\w\\.-]+', ' ', txt, flags=re.MULTILINE)\n",
    "    \n",
    "    # Replace words like sooooooo with so\n",
    "    txt = ''.join(''.join(s)[:2] for _, s in itertools.groupby(txt))\n",
    "    \n",
    "    # Remove punctuation from text\n",
    "    txt = ''.join([c for c in text if c not in punctuation])\n",
    "    \n",
    "    # Remove all symbols\n",
    "    txt = re.sub(r'[^A-Za-z\\s]',r' ',txt)\n",
    "    txt = re.sub(r'\\n',r' ',txt)\n",
    "    \n",
    "    if lowercase:\n",
    "        txt = \" \".join([w.lower() for w in txt.split()])\n",
    "        \n",
    "    if remove_stops:\n",
    "        txt = \" \".join([w for w in txt.split() if w not in stop_words])\n",
    "        \n",
    "    if stemming:\n",
    "        st = PorterStemmer()\n",
    "        txt = \" \".join([st.stem(w) for w in txt.split()])\n",
    "    \n",
    "    if lemmatization:\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        txt = \" \".join([wordnet_lemmatizer.lemmatize(w, pos='v') for w in txt.split()])\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emoji = [':-)', ':)', ':-]', ':]', ':-3', ':3', ':->', ':>', '8-)', '8)', ':-}', ':}', ':o)', ':c)', ':^)', '=]', '=)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=D', '=3', 'B^D', ':-))', ';-)', ';)', '*-)', '*)', ';-]', ';]', ';^)', ';D', ':-P', ':P', 'X-P', 'x-p', ':-p', ':p', ':-?', ':?', ':-?', ':?', ':-b', ':b', '=p', '>:P', ':*', ':-*', '^.^', '^_^', '^-^', 'xd']\n",
    "neg_emoji = [':-(', ':(', ':-c', ':c', ':-<', ':<', ':-[', ':[', ':-||', '>:[', ':{', ':@', '>:(', ':-/', ':/', '>:\\\\', '>:/', ':\\\\', '=/', '=\\\\', ':L', '=L', ':S', ':-|', ':|', ':-X', ':X', '-.-', '-,-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of positive emoji in the text ##\n",
    "train[\"number_of_positive_emo\"] = train['review'].apply(lambda x: len([c for c in str(x).split() if c in pos_emoji]))\n",
    "test[\"number_of_positive_emo\"] = test['review'].apply(lambda x: len([c for c in str(x).split() if c in pos_emoji]))\n",
    "\n",
    "## Number of negative emoji in the text ##\n",
    "train[\"number_of_negative_emo\"] = train['review'].apply(lambda x: len([c for c in str(x).split() if c in neg_emoji]))\n",
    "test[\"number_of_negative_emo\"] = test['review'].apply(lambda x: len([c for c in str(x).split() if c in neg_emoji]))\n",
    "\n",
    "train[\"num_words\"] = train[\"review\"].apply(lambda x: len(str(x).split()))\n",
    "test[\"num_words\"] = test[\"review\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "## Number of unique words in the text ##\n",
    "train[\"num_unique_words\"] = train[\"review\"].apply(lambda x: len(set(str(x).split())))\n",
    "test[\"num_unique_words\"] = test[\"review\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "## Number of characters in the text ##\n",
    "train[\"num_chars\"] = train[\"review\"].apply(lambda x: len(str(x)))\n",
    "test[\"num_chars\"] = test[\"review\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "## Number of stopwords in the text ##\n",
    "train[\"num_stopwords\"] = train[\"review\"].apply(lambda x: len([w for w in str(x).lower().split() if w in stop_words]))\n",
    "test[\"num_stopwords\"] = test[\"review\"].apply(lambda x: len([w for w in str(x).lower().split() if w in stop_words]))\n",
    "\n",
    "## Number of punctuations in the text ##\n",
    "train[\"num_punctuations\"] =train['review'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "test[\"num_punctuations\"] =test['review'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "\n",
    "## Number of title case words in the text ##\n",
    "train[\"num_words_upper\"] = train[\"review\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "test[\"num_words_upper\"] = test[\"review\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "\n",
    "## Number of title case words in the text ##\n",
    "train[\"num_words_title\"] = train[\"review\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "test[\"num_words_title\"] = test[\"review\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "\n",
    "## Average length of the words in the text ##\n",
    "train[\"mean_word_len\"] = train[\"review\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test[\"mean_word_len\"] = test[\"review\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train = train.copy()\n",
    "cleaned_test = test.copy()\n",
    "# clean comments\n",
    "cleaned_train['review'] = train['review'].map(lambda x: cleanData(x, lowercase=True, remove_stops=True, stemming=True, lemmatization = True))\n",
    "cleaned_test['review'] = test['review'].map(lambda x: cleanData(x, lowercase=True, remove_stops=True, stemming=True, lemmatization = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "e64cf3a3-4e5f-4d24-82ab-2a6aa295d542",
    "_uuid": "91a34312dc84df21cc7e1a908caba1e81515ec90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anuragsharma/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "cleaned_test['emotion'] = np.nan\n",
    "alldata = pd.concat([cleaned_train, cleaned_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_cell_guid": "7ed1b777-5653-4459-bf28-d9f94418cf9c",
    "_uuid": "6ea9baf9c61a51f99847999a8fb0c9a3cee795aa"
   },
   "outputs": [],
   "source": [
    "tfidfvec = TfidfVectorizer(analyzer='word', ngram_range = (1,3),min_df = 10,max_df=0.8, sublinear_tf=True,\n",
    "                             use_idf=True)\n",
    "tfidfdata = tfidfvec.fit_transform(alldata['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_cell_guid": "cbda6bff-8953-442b-8ae0-4634b4195afc",
    "_uuid": "14ed330ce86abaada9a9ce4b96660db41b387572"
   },
   "outputs": [],
   "source": [
    "# create dataframe for features\n",
    "tfidf_df = pd.DataFrame(tfidfdata.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_cell_guid": "baed0500-673b-4827-a51d-79fd21d2befa",
    "_uuid": "d5ce81a994adbfce33ede953d301bdde9e679b84"
   },
   "outputs": [],
   "source": [
    "tfidf_df.columns = ['col' + str(x) for x in tfidf_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_cell_guid": "aa8b8638-26f7-4f1f-9a39-11a42297f6a2",
    "_uuid": "d3e67eca7d7a196cba97bb175908b84e654c5cde"
   },
   "outputs": [],
   "source": [
    "tfid_df_train = tfidf_df[:len(train)]\n",
    "tfid_df_test = tfidf_df[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_cell_guid": "a30624db-0007-4e4e-85a9-184e2054fd1c",
    "_uuid": "d9f1cd3a4c6fb14aa24dbb60cd9b35e777233962"
   },
   "outputs": [],
   "source": [
    "# split the merged data file into train and test respectively\n",
    "train_feats = alldata[~pd.isnull(alldata.emotion)]\n",
    "test_feats = alldata[pd.isnull(alldata.emotion)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_cell_guid": "9456aa2f-5f07-4d61-8397-29b4422e22f3",
    "_uuid": "c721949b7e2b7e2b7b60ac8afac0514ac0d507b1"
   },
   "outputs": [],
   "source": [
    "# merge into a new data frame with tf-idf features\n",
    "cols = ['number_of_positive_emo','number_of_negative_emo','num_words','num_unique_words','num_chars','num_stopwords','num_punctuations','num_words_upper','num_words_title','mean_word_len']\n",
    "train_feats2 = pd.concat([train_feats[cols], tfid_df_train], axis=1)\n",
    "test_feats2 = pd.concat([test_feats[cols], tfid_df_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Upsampling to balance the classes\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_sample(train_feats2, train['emotion'].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([622, 622, 622, 622, 622, 622])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e6c474d2-28fe-4fbc-8d99-8ae1b0361895",
    "_uuid": "f8ece874bf7ae4cfc7e191850e4a09d0b7cd63a4"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using Random Forest we got highest validation score. Accuracy can be increased using ensembling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()#LogisticRegression(penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56084656 0.51322751 0.55107527 0.57258065 0.5188172  0.63172043\n",
      " 0.76612903 0.78763441 0.79032258 0.77150538]\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes 2 - tfidf is giving higher CV score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "print(cross_val_score(model, X_train_res, y_train_res, cv=10, scoring=make_scorer(accuracy_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_feats2, train['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_feats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result['review'] = test_reviews\n",
    "result['emotion'] = pred\n",
    "mapping = {0:'neutral', 1:'worry', 2:'sadness', 3:'happiness', 4:'love', 5:'anger'}\n",
    "result = result.replace({'emotion':mapping})\n",
    "\n",
    "result.to_csv(\"tf_idf_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@gfalcone601 that little girl on BGT! how sad!...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today I wrote two songs (one for temple which ...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Have 3 of the 5 grandbabies again today. 19 mo...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>on my way to driver's training</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@rmolden Yes, maybe, but for today, I write</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  emotion\n",
       "0  @gfalcone601 that little girl on BGT! how sad!...  sadness\n",
       "1  Today I wrote two songs (one for temple which ...    worry\n",
       "2  Have 3 of the 5 grandbabies again today. 19 mo...     love\n",
       "3                     on my way to driver's training  neutral\n",
       "4        @rmolden Yes, maybe, but for today, I write  neutral"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "_cell_guid": "ea38022d-7ec1-4cde-ba21-354f19056f78",
    "_uuid": "69d745d1da9b39217e277e01921dcb4d7d5ab029"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 140\n",
    "MAX_NB_WORDS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "_cell_guid": "b306f4e2-3720-478e-a514-d93fb17de9c4",
    "_uuid": "4e9ddcf9a8c676bce93d52d189e36c02c583fd2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data tensor: (2200, 400)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(lower=False, filters='',num_words = MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(train['review'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(train['review'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test['review'])\n",
    "\n",
    "train_data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of train data tensor:', train_data.shape)\n",
    "\n",
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "nb_words = (np.max(train_data) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "_cell_guid": "56daceee-3fcc-4ff0-b4a3-52907f2cad78",
    "_uuid": "d563a71e30ba48204a856a4d354c516d7e441b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 400, 100)          894400    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 400, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 1,012,422\n",
      "Trainable params: 1,012,422\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.recurrent import LSTM, GRU\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words,100,input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "_cell_guid": "f2948dd1-2c3a-4dc2-9b9c-1300a445abd9",
    "_uuid": "bd79226f8703dae0bae909a4b739d44e62b26490"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anuragsharma/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1760 samples, validate on 440 samples\n",
      "Epoch 1/25\n",
      "1760/1760 [==============================] - 50s 28ms/step - loss: 1.6314 - acc: 0.2773 - val_loss: 1.5835 - val_acc: 0.2750\n",
      "Epoch 2/25\n",
      "1760/1760 [==============================] - 46s 26ms/step - loss: 1.5836 - acc: 0.2841 - val_loss: 1.5783 - val_acc: 0.2750\n",
      "Epoch 3/25\n",
      "1760/1760 [==============================] - 44s 25ms/step - loss: 1.5717 - acc: 0.2869 - val_loss: 1.5780 - val_acc: 0.2750\n",
      "Epoch 4/25\n",
      "1760/1760 [==============================] - 42s 24ms/step - loss: 1.4801 - acc: 0.2989 - val_loss: 1.5367 - val_acc: 0.3136\n",
      "Epoch 5/25\n",
      "1760/1760 [==============================] - 45s 26ms/step - loss: 1.1115 - acc: 0.5074 - val_loss: 1.7058 - val_acc: 0.2682\n",
      "Epoch 6/25\n",
      "1760/1760 [==============================] - 43s 24ms/step - loss: 0.7186 - acc: 0.7364 - val_loss: 1.8903 - val_acc: 0.2773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3d5f1be0>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train['emotion'].values, validation_split=0.2, nb_epoch=25, batch_size=32, callbacks=[EarlyStopping(patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "_cell_guid": "b8e69172-b0a1-42b4-859c-cd31ef517ba5",
    "_uuid": "6b0c84c0fc96d5498daf7802c048791111173f33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03176159, 0.04356652, 0.25882858, 0.02311728, 0.00376215,\n",
       "        0.00202857],\n",
       "       [0.0138741 , 0.00340667, 0.00944322, 0.46270207, 0.5968051 ,\n",
       "        0.00388942],\n",
       "       [0.05287918, 0.03730596, 0.06956759, 0.04091349, 0.01069351,\n",
       "        0.00145889],\n",
       "       ...,\n",
       "       [0.21452421, 0.07213514, 0.04195243, 0.0144422 , 0.00363017,\n",
       "        0.00207085],\n",
       "       [0.6165208 , 0.04831154, 0.02218549, 0.01699293, 0.03509303,\n",
       "        0.00465251],\n",
       "       [0.04521891, 0.11928763, 0.03079759, 0.02609345, 0.00087572,\n",
       "        0.00076186]], dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_data)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for p in pred:\n",
    "    mn,idx = max((p[i],i) for i in range(len(p)))\n",
    "    pred_list.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "_cell_guid": "5b32d9c7-fe29-4a1b-86a0-0094f730b1e6",
    "_uuid": "65ef574ede08f8dd0bdf8c6bac59fae7aa2c4b49"
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result['review'] = test_reviews\n",
    "result['emotion'] = pred_list\n",
    "mapping = {0:'neutral', 1:'worry', 2:'sadness', 3:'happiness', 4:'love', 5:'anger'}\n",
    "result = result.replace({'emotion':mapping})\n",
    "\n",
    "result.to_csv(\"nn_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "_cell_guid": "931d1863-9d58-4a64-bceb-6d36b2bd76cf",
    "_uuid": "f318b5e0b21c88acf4d7cf7ba8a95f4145f252cc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@gfalcone601 that little girl on BGT! how sad!...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today I wrote two songs (one for temple which ...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Have 3 of the 5 grandbabies again today. 19 mo...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>on my way to driver's training</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@rmolden Yes, maybe, but for today, I write</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  emotion\n",
       "0  @gfalcone601 that little girl on BGT! how sad!...  sadness\n",
       "1  Today I wrote two songs (one for temple which ...     love\n",
       "2  Have 3 of the 5 grandbabies again today. 19 mo...  sadness\n",
       "3                     on my way to driver's training  neutral\n",
       "4        @rmolden Yes, maybe, but for today, I write    worry"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "_cell_guid": "3478cdc4-2d0e-4b93-b86e-c00fd0b3556d",
    "_uuid": "341ee4a18b5ef063dfb4b12078c2e3fe5d1e2160"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral      419\n",
       "worry        290\n",
       "sadness      100\n",
       "love          83\n",
       "happiness     51\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
